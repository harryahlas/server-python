{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Start with cmd: jupyter notebook C:\\Development\\github\\server-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init('/mnt/c/Users/Spark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.sql(\"select 'spark' as hello \")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "\n",
    "#sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqlContext = pyspark.SQLContext(pyspark.SparkContext())\n",
    "sqlContext = pyspark.SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recruiting = sqlContext.read.format('jdbc').options(\n",
    "          url='jdbc:mysql://localhost:3306/hrsample',\n",
    "          #driver='com.mysql.jdbc.Driver',\n",
    "          #driver='com.mysql.cj.jdbc.Driver',\n",
    "          dbtable='recruiting',\n",
    "          user='newuser',\n",
    "          password='newuser').load()\n",
    "\n",
    "deskhistory = sqlContext.read.format('jdbc').options(\n",
    "          url='jdbc:mysql://localhost:3306/hrsample',\n",
    "          #driver='com.mysql.jdbc.Driver',\n",
    "          #driver='com.mysql.cj.jdbc.Driver',\n",
    "          dbtable='deskhistory',\n",
    "          user='newuser',\n",
    "          password='newuser').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(employee_num=16684, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recruiting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"SPARK_CLASSPATH\"] = 'C:/Users/Spark/jars/postgresql-42.2.9.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postgres test\n",
    "# Download the PostgreSQL JDBC Driver from https://jdbc.postgresql.org/download.html.\n",
    "# anaconda prompt: export SPARK_CLASSPATH=C:\\Program Files\\PostgreSQL\n",
    "# none of above, update path using above\n",
    "#CHECK ERROR HERE\n",
    "employeeinfo = sqlContext.read.format('jdbc').options(\n",
    "          url='jdbc:postgresql://localhost:5432/postgres',\n",
    "          #driver='com.mysql.jdbc.Driver',\n",
    "          #driver='com.mysql.cj.jdbc.Driver',\n",
    "          dbtable='employeeinfo',\n",
    "          user='newuser',\n",
    "          password='newuser').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(employee_num=3, first_name='Lana', last_name='Chrostowski', city='Utica', state='MS'),\n",
       " Row(employee_num=20, first_name='Justine', last_name='Kopiasz', city='Milnor', state='ND'),\n",
       " Row(employee_num=21, first_name='Claude', last_name='Feldman', city='Woodville', state='AL'),\n",
       " Row(employee_num=38, first_name='Ronald', last_name='Finona', city='West Glover', state='VT'),\n",
       " Row(employee_num=39, first_name='Stewart', last_name='Pruess', city='Martin', state='OH')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employeeinfo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(employee_num=16684, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=29068, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=19507, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=7504, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=2549, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=8869, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=21041, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=9968, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=34070, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999),\n",
       " Row(employee_num=1265, recruiting_source='NA', first_contact_date=datetime.date(1999, 1, 1), recruiter_employee_num=9999999)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recruiting.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlite setup and connection\n",
    "# driver here: https://bitbucket.org/xerial/sqlite-jdbc/downloads/sqlite-jdbc-3.8.6.jar\n",
    "# store to C:\\Program Files\\sqlite\\sqlite-jdbc-3.8.6.jar (I don't think this works)\n",
    "# also store here: C:\\Users\\Spark\\jars\\sqlite-jdbc-3.8.6.jar\n",
    "# NOTUSED:pyspark --conf spark.executor.extraClassPath=<jdbc.jar> --driver-class-path <jdbc.jar> --jars <jdbc.jar> --master <master-URL>\n",
    "# chmod 775 /home/newuser/anaconda3/lib/python3.7/site-packages/pyspark/java_gateway.py\n",
    "# pyspark --conf spark.executor.extraClassPath=mnt/c/sqlite/sqlite-jdbc-3.8.6.jar --driver-class-path mnt/c/sqlite/sqlite-jdbc-3.8.6.jar --jars mnt/c/sqlite/sqlite-jdbc-3.8.6.jar \n",
    "dfsqlite = sqlContext.read.format('jdbc').options(url='jdbc:sqlite:my_db.sqlite3', dbtable='deskhistory',driver='org.sqlite.JDBC').load()\n",
    "\n",
    "#sqlCtx.read.format(\"jdbc\").options(url =\"jdbc:sqlite:E:/Databases/devtest.db\", driver=\"org.sqlite.JDBC\", dbtable=\"bin_data\").load().take(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(employee_num=154797, desk_id=1, desk_id_start_date=10592.0, desk_id_end_date=17897.0, termination_flag=0, promotion_flag=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsqlite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsqlite = sqlContext.read.format('jdbc').\\\n",
    "\n",
    "     options(url='jdbc:sqlite:my_db.sqlite3',\\\n",
    "\n",
    "     dbtable='deskhistory',driver='org.sqlite.JDBC').load()\n",
    "\n",
    "dfsqlite.printSchema() to see your schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Yuck \n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = '/mnt/c/Users/Anyone/Desktop/Toss/my_db.sqlite3'\n",
    "\n",
    "query = 'SELECT * from deskhistory'\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "a_pandas_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "a_spark_df = SQLContext.createDataFrame(a_pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_rec = employeeinfo.join(recruiting, employeeinfo.employee_num == recruiting.employee_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_rec.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below not needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
